{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBbjrmqjkOkZBWUJECkNbu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirmal-ank/Transformers/blob/main/NLU_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWly3HtBUwLd"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNKY6I4RU83n",
        "outputId": "a7c2ea70-29cf-4cd0-f620-ddc874c59807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "named_params = list(model.named_parameters())"
      ],
      "metadata": {
        "id": "Yg8zcmBVVFRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The BERT model has {:} different named parameters.\\n\".format(len(named_params)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHvHG2pYVLRD",
        "outputId": "b2ad1b7f-cd37-4ef1-8486-d0117dd592b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 199 different named parameters.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in named_params[0:5]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0],str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ-5WXHxVeHU",
        "outputId": "14331bf8-0b40-48d7-a615-15fe6a695470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings.word_embeddings.weight                       (30522, 768)\n",
            "embeddings.position_embeddings.weight                     (512, 768)\n",
            "embeddings.token_type_embeddings.weight                     (2, 768)\n",
            "embeddings.LayerNorm.weight                                   (768,)\n",
            "embeddings.LayerNorm.bias                                     (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in named_params[5:21]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0],str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti8cKgucWEGs",
        "outputId": "d7998901-fae9-41c8-800a-2abc9323d8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder.layer.0.attention.self.query.weight               (768, 768)\n",
            "encoder.layer.0.attention.self.query.bias                     (768,)\n",
            "encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
            "encoder.layer.0.attention.self.key.bias                       (768,)\n",
            "encoder.layer.0.attention.self.value.weight               (768, 768)\n",
            "encoder.layer.0.attention.self.value.bias                     (768,)\n",
            "encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
            "encoder.layer.0.attention.output.dense.bias                   (768,)\n",
            "encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
            "encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
            "encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
            "encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
            "encoder.layer.0.output.dense.weight                      (768, 3072)\n",
            "encoder.layer.0.output.dense.bias                             (768,)\n",
            "encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
            "encoder.layer.0.output.LayerNorm.bias                         (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in named_params[-2:]:\n",
        "  print(\"{:<55} {:>12}\".format(p[0],str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfX1gRvfWHb7",
        "outputId": "108bd90f-a2a3-4a56-ddef-ffd7137fc563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pooler.dense.weight                                       (768, 768)\n",
            "pooler.dense.bias                                             (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "9CvpfUVfWPNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens= tokenizer.encode(\"Rajesh loves to study about transformers.\")"
      ],
      "metadata": {
        "id": "rT3ONmVPWdDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model(torch.tensor(tokenizer.encode(tokens)).unsqueeze(0))"
      ],
      "metadata": {
        "id": "TJNZHPhuWk0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.last_hidden_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QJxjXKlXJPb",
        "outputId": "d8ee44af-5ffc-47f1-a8f6-9ffaa1f877f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1479, -0.2184, -0.2849,  ..., -0.3093,  1.0494,  0.2841],\n",
              "         [-0.0955, -0.1527, -0.2696,  ..., -0.3192,  1.0766,  0.2047],\n",
              "         [ 1.2062, -0.8747, -0.8963,  ...,  0.2876,  0.5944, -0.1765],\n",
              "         ...,\n",
              "         [ 0.2162, -0.9268, -0.1171,  ...,  0.0396,  0.9059, -0.8442],\n",
              "         [ 0.8353, -0.0064,  0.0195,  ...,  0.1884, -0.2348, -0.5020],\n",
              "         [ 0.8353, -0.0063,  0.0201,  ...,  0.1887, -0.2346, -0.5024]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.pooler_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew4J7XrlXPDC",
        "outputId": "61916980-275b-4d36-ac34-1e56b9d3987f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.pooler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kppN8YbDXY4z",
        "outputId": "1f40adb4-ca37-4c3e-a49b-663b101472aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertPooler(\n",
              "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (activation): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_embedding = response.last_hidden_state[:,0,:].unsqueeze(0)"
      ],
      "metadata": {
        "id": "wjJgfbRzXfla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLS_embedding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZBs8MutXoai",
        "outputId": "bff10c3a-c3a6-4780-840e-a281ea4a00b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.pooler(CLS_embedding).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-BKXPhvXrmb",
        "outputId": "b373290d-a8d9-4b92-8f11-a83c5766b1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(model.pooler(CLS_embedding) == response.pooler_output).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcoNAlQXXxpC",
        "outputId": "757b1310-b1b8-4faf-d5f5-3fba3dd449d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = 0\n",
        "for p in model.parameters():\n",
        "  if len(p.shape) ==2:\n",
        "    total_params += p.shape[0] * p.shape[1]\n",
        "print(f\"Total parameters = {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASi9QpMnYA2x",
        "outputId": "31b7d8f7-2c2d-42ac-e64c-53e2f381b66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters = 109360128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordPiece tokenization"
      ],
      "metadata": {
        "id": "6cmxqMC5Z7US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of BERT base vocabulary = {len(tokenizer.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhK9uFSbYSGZ",
        "outputId": "a83d7e35-dfe1-4af4-a2e6-fdadc3441465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of BERT base vocabulary = 30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"I love my pet Python.\"\n",
        "text2 = \"I love coding in Python.\""
      ],
      "metadata": {
        "id": "a3X31wgEeHfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens1 = tokenizer.encode(text1)\n",
        "tokens2 = tokenizer.encode(text2)"
      ],
      "metadata": {
        "id": "OaC-78yweYfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in tokens1:\n",
        "  print(tokenizer.decode([t]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh5iiDrXegDC",
        "outputId": "770b5c5c-95b7-4ade-d0d8-f4d57e2b1e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\n",
            "i\n",
            "love\n",
            "my\n",
            "pet\n",
            "python\n",
            ".\n",
            "[SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in tokens2:\n",
        "  print(tokenizer.decode([t]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSBffamBjH4p",
        "outputId": "40c77671-5698-414b-a3de-198926cdfbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\n",
            "i\n",
            "love\n",
            "coding\n",
            "in\n",
            "python\n",
            ".\n",
            "[SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Niel\" in tokenizer.vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgwe0uhlerRK",
        "outputId": "fe60e9ef-86d0-4eac-cf5c-b8f84da0634c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for_unknown = tokenizer.encode(\"Niel\")"
      ],
      "metadata": {
        "id": "afvrMNhFfG4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in for_unknown:\n",
        "  print(tokenizer.decode([t]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9dwqBEZfL5B",
        "outputId": "371eb53b-70e9-4a4f-b64a-9eab833eeaf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\n",
            "ni\n",
            "##el\n",
            "[SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_plus1 = tokenizer.encode_plus(text1)\n",
        "tokens_plus2 = tokenizer.encode_plus(text2)"
      ],
      "metadata": {
        "id": "jf7A-X1NfaiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens_plus1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa9PckElf6lR",
        "outputId": "8757c05f-d0fa-4450-8717-d5c92831bd54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 1045, 2293, 2026, 9004, 18750, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "general = model(torch.tensor(tokens1).unsqueeze(0))[0][:,5,:].detach().numpy()\n",
        "code = model(torch.tensor(tokens2).unsqueeze(0))[0][:,5,:].detach().numpy()\n"
      ],
      "metadata": {
        "id": "kYODRMx_f8yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "general_embedding = model(torch.tensor(tokenizer.encode(\"snake\")).unsqueeze(0))[0][:,1,:].detach().numpy()\n",
        "programming_embedding = model(torch.tensor(tokenizer.encode(\"programming\")).unsqueeze(0))[0][:,1,:].detach().numpy()\n"
      ],
      "metadata": {
        "id": "NHREgNYAg2TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ojQ4T3PhS4g",
        "outputId": "78db8525-17b1-41b9-ea90-274f5675d9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "programming_embedding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7D2TL_BhX0P",
        "outputId": "05da24bd-d1c9-432d-b03c-6bad1141cdbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(code, programming_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djK_oERphbLw",
        "outputId": "e8f8f3ce-3dba-408b-fe1c-c17faa2f7e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.28580743]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(code, general_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DziN7G3hg44",
        "outputId": "833b2769-0bb7-4d32-ec65-15941108c85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.30203456]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8bby7A_QhlpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Many Embeddings of BERT"
      ],
      "metadata": {
        "id": "jxnzpnb4leK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJCPmie5lgr9",
        "outputId": "84ae3626-9853-4a9f-90be-42f292dfa3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertEmbeddings(\n",
              "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "  (position_embeddings): Embedding(512, 768)\n",
              "  (token_type_embeddings): Embedding(2, 768)\n",
              "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex_phrase = \"I am Niel\""
      ],
      "metadata": {
        "id": "z7Edg7ekljrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_pt= tokenizer.encode(ex_phrase,return_tensors=\"pt\")\n",
        "tokens_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUQExOYfluy9",
        "outputId": "6ffa4c61-264a-4f4e-a25a-0f458256f298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 1045, 2572, 9152, 2884,  102]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings.word_embeddings(torch.tensor(tokenizer.encode(ex_phrase,return_tensors=\"pt\").clone().detach().requires_grad_(False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZxTkuJjlzJF",
        "outputId": "598e12f8-e877-4b37-b123-c7204c937d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-e936a6e7f9dd>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  model.embeddings.word_embeddings(torch.tensor(tokenizer.encode(ex_phrase,return_tensors=\"pt\").clone().detach().requires_grad_(False)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
              "         [-0.0211,  0.0059, -0.0179,  ...,  0.0163,  0.0122,  0.0073],\n",
              "         [-0.0437, -0.0150,  0.0029,  ..., -0.0282,  0.0474, -0.0448],\n",
              "         [-0.0163, -0.0844, -0.0084,  ..., -0.0216,  0.0330, -0.0381],\n",
              "         [-0.0439,  0.0315, -0.0015,  ..., -0.0086, -0.0030,  0.0044],\n",
              "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings.word_embeddings(torch.tensor(tokenizer.encode(\"I am Robert\",return_tensors=\"pt\").clone().detach().requires_grad_(False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxvS-lr-l5F1",
        "outputId": "d366d407-e219-4554-94be-9ebc80e96822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-59-aecf002f613f>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  model.embeddings.word_embeddings(torch.tensor(tokenizer.encode(\"I am Robert\",return_tensors=\"pt\").clone().detach().requires_grad_(False)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
              "         [-0.0211,  0.0059, -0.0179,  ...,  0.0163,  0.0122,  0.0073],\n",
              "         [-0.0437, -0.0150,  0.0029,  ..., -0.0282,  0.0474, -0.0448],\n",
              "         [-0.0033, -0.0325, -0.0210,  ...,  0.0133, -0.0615, -0.0664],\n",
              "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings.position_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JiduHnNmdH9",
        "outputId": "366474ec-0df0-4b61-a054-1ac15d9038d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(512, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings.position_embeddings(torch.tensor(range(6))).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSZNRRLsmh0M",
        "outputId": "72af0403-7bf1-4545-e7de-d7f1427d3033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings.token_type_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRalF9KomxcM",
        "outputId": "039816ab-d7cb-4fdd-ea5e-9a3970e30fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(2, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings.token_type_embeddings(torch.tensor([0]*6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93h-ySZFndrU",
        "outputId": "a8d87dee-e648-461e-cdf4-cd7ed1415a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
              "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
              "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
              "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
              "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
              "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings.LayerNorm(\n",
        "    model.embeddings.word_embeddings(torch.tensor(tokenizer.encode(ex_phrase,return_tensors=\"pt\").clone().detach().requires_grad_(False))) + \\\n",
        "    model.embeddings.position_embeddings(torch.tensor(range(6))) + \\\n",
        "    model.embeddings.token_type_embeddings(torch.tensor([0]*6))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vigLWLkng3k",
        "outputId": "cecbb16e-04a8-442b-ca25-e502411ccc3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-60114e8c16c4>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  model.embeddings.word_embeddings(torch.tensor(tokenizer.encode(ex_phrase,return_tensors=\"pt\").clone().detach().requires_grad_(False))) + \\\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
              "           3.8253e-02,  1.6400e-01],\n",
              "         [-3.4024e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
              "           8.9008e-01,  1.6575e-01],\n",
              "         [-6.3496e-01,  1.9748e-01,  2.5116e-01,  ..., -4.0819e-02,\n",
              "           1.3468e+00, -6.9357e-01],\n",
              "         [ 3.3420e-02, -1.0170e+00, -1.2740e-02,  ...,  2.2663e-01,\n",
              "           9.4980e-01, -4.0098e-01],\n",
              "         [-4.1618e-01,  8.9394e-01,  3.3912e-01,  ...,  4.1110e-01,\n",
              "           3.7617e-01,  4.6739e-01],\n",
              "         [-3.2507e-01, -3.1879e-01, -1.1632e-01,  ..., -3.9602e-01,\n",
              "           4.1120e-01, -7.7552e-02]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.embeddings(tokenizer.encode(ex_phrase,return_tensors=\"pt\")).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4P09uo0n7-E",
        "outputId": "413cdbdc-4a6c-4765-e01f-5a72059525f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJ2iL-XroHjT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}